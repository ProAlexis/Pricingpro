name: Scrape Market Rates
on:
  schedule:
    # Tous les lundis √† 2h du matin (UTC)
    - cron: "0 2 * * 1"
  workflow_dispatch: # Permet de lancer manuellement depuis GitHub

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 15 # Timeout de s√©curit√©

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "18"
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Test Supabase connection
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}
        run: |
          echo "üîç Testing database connection..."
          node test-scraper-connection.js 2>&1 | tee connection-test.log
        continue-on-error: true

      - name: Run multi-source scraper
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          echo "üöÄ Starting scraper..."
          echo "‚è∞ Start time: $(date)"
          node run-scraper.js 2>&1 | tee scraper-output.log
          echo "‚è∞ End time: $(date)"

      - name: Notify on success
        if: success()
        run: echo "‚úÖ Scraping completed successfully! 2070+ rates updated."

      - name: Notify on failure
        if: failure()
        run: echo "‚ùå Scraping failed!"

      - name: Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@v3
        with:
          name: scraper-logs
          path: |
            scraper-output.log
            connection-test.log
